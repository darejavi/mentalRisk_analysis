# -*- coding: utf-8 -*-
"""ClientServer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tLVHaiyUs6yjZ2lFvOUG7h24Zb1UFNF6

# Access the MentalRiskEs data and interact with the server

This notebook has been developed by the [SINAI](https://sinai.ujaen.es/) research group for its usage in the [MentalRiskES](https://sites.google.com/view/mentalriskes2025/) evaluation campaign at IberLEF 2025.

**NOTE 1**: Please visit the [MentalRiskES competition website](https://sites.google.com/view/mentalriskes2025/evaluation) to read the instructions about how to download the data and interact with the server to send the predictions of your system.

**NOTE 2**: Along the code, please replace "URL" by the URL server and "TOKEN" by your personal token.

Remember this is a support to help you to develop your own system of communication with our server. We recommend you to download it as a Python script instead of working directly on colab and adapt the code to your needs.

# Install CodeCarbon package
Read the [documentation](https://mlco2.github.io/codecarbon/) about the library if necessary. Remember that we provide a [CodeCarbon notebook](https://colab.research.google.com/drive/1boavnGOir0urui8qktbZaOmOV2pS5cn6?usp=sharing) with the example in its specific use in our competition.
"""

"""# Import libraries"""

import requests, zipfile, io
from requests.adapters import HTTPAdapter, Retry
from typing import List, Dict
import random
import json
import os
import pandas as pd
from codecarbon import EmissionsTracker
import sys
import joblib
from sentence_transformers import SentenceTransformer
from transformers import RobertaTokenizer, RobertaModel
import torch
from sklearn.neighbors import KNeighborsClassifier
import torch.nn.functional as F
from transformers import AutoTokenizer, AutoModel


"""# Endpoints
These URL addresses are necessary for the connection to the server.

**IMPORTANT:** Replace "URL" by the URL server and "TOKEN" by your user token.
"""

URL = "http://s3-ceatic.ujaen.es:8036"
TOKEN = "fa8f7a4d0b4d854b90005d14c39f313f"

# Download endpoints
ENDPOINT_DOWNLOAD_TRIAL = URL+"/{TASK}/download_trial/{TOKEN}"
ENDPOINT_DOWNLOAD_TRAIN = URL+"/{TASK}/download_train/{TOKEN}"

# Trial endpoints
ENDPOINT_GET_MESSAGES_TRIAL = URL+"/{TASK}/getmessages_trial/{TOKEN}"
ENDPOINT_SUBMIT_DECISIONS_TRIAL = URL+"/{TASK}/submit_trial/{TOKEN}/{RUN}"

# Test endpoints
ENDPOINT_GET_MESSAGES = URL+"/{TASK}/getmessages/{TOKEN}"
ENDPOINT_SUBMIT_DECISIONS = URL+"/{TASK}/submit/{TOKEN}/{RUN}"



"""# Client Server
This class simulates communication with our server. The following code established the conection with the server client and simulate the GET and POST requests.

**IMPORTANT NOTE:** Please pay attention to the basic functions and remember that it is only a base for your system.
"""


class Client_task1_2:
    """ Client communicating with the official server.
        Attributes:
            token (str): authentication token
            number_of_runs (int): number of systems. Must be 3 in order to advance to the next round.
            tracker (EmissionsTracker): object to calculate the carbon footprint in prediction

    """
    def __init__(self, task:str, token: str, number_of_runs: int, tracker: EmissionsTracker):
        self.task = task
        self.token = token
        self.number_of_runs = number_of_runs
        self.tracker = tracker
        self.relevant_cols = ['duration', 'emissions', 'cpu_energy', 'gpu_energy',
                              'ram_energy','energy_consumed', 'cpu_count', 'gpu_count',
                              'cpu_model', 'gpu_model', 'ram_total_size','country_iso_code']
        #Inicializar todas las variables necesarias
        self.total_users=set()
        self.round_users=set()
        self.flagged_users_run1=[]
        self.sended_users_run1=[]
        self.non_predicted_user_run1=[]
        self.flagged_users_run2=[]
        self.sended_users_run2=[]
        self.non_predicted_user_run2=[]
        self.flagged_users_run3=[]
        self.sended_users_run3=[]
        self.non_predicted_user_run3=[]
        self.embedder = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
        self.user_texts_run2 = {}
        self.user_probs= {}
        self.user_texts= {}
        self.THRESHOLD = 0.6
        self.THRESHOLD_msg = 0.4
        self.model = joblib.load("svm_gambling_text.pkl")
        self.model_mensajes = joblib.load("gambling_detector_per_msg.pkl")



    def get_messages(self, retries: int, backoff: float) -> Dict:
        """ Allows you to download the test data of the task by rounds.
            Here a GET request is sent to the server to extract the data.
            Args:
              retries (int): number of calls on the server connection
              backoff (float): time between retries
        """
        session = requests.Session()
        retries = Retry(
                        total = retries,
                        backoff_factor = backoff,
                        status_forcelist = [500, 502, 503, 504]
                        )
        session.mount('https://', HTTPAdapter(max_retries=retries))

        response = session.get(ENDPOINT_GET_MESSAGES.format(TASK=self.task, TOKEN=self.token)) # ENDPOINT

        if response.status_code != 200:
          print("GET - Task {} - Status Code {} - Error: {}".format(self.task, str(response.status_code), str(response.text)))
          return []
        else:
          return json.loads(response.content)

    def submit_decission(self, messages: List[Dict], emissions: Dict, retries: int, backoff: float):
        """ Allows you to submit the decisions of the task by rounds.
            The POST requests are sent to the server to send predictions and carbon emission data
            Args:
              messages (List[Dict]): Message set of the current round
              emissions (Dict): carbon footprint generated in the prediction
              retries (int): number of calls on the server connection
              backoff (float): time between retries
        """
        decisions_run0 = {}
        decisions_run1 = {}
        decisions_run2 = {}
        type_addiction_list = ["betting", "onlinegaming", "betting", "trading"]
        type_addiction_decision = {}
        round_number = messages[0]["round"] if messages else "?"
        # You must create the appropriate structure to send the predictions according to each task

        #Mandar como 1 los usuarios detectados como adictos, y mandar como 0 los que ya hayan acabado mensajes
        print(f"\n======= ROUND {round_number} =======")
        print(f"Run 1: Users predicted {self.flagged_users_run1}:")
        for nick in self.flagged_users_run1:
            decisions_run0[nick] = 1
        
        print(f"Run 2: Users predicted {self.flagged_users_run2}:")
        for nick in self.flagged_users_run2:
            decisions_run1[nick] = 1
        
        print(f"Run 3: Users predicted {self.flagged_users_run3}:")
        for nick in self.flagged_users_run3:
            decisions_run2[nick] = 1

        usarios_acabados = self.total_users - self.round_users

        for nick in usarios_acabados:
            decisions_run0[nick] = 0
            decisions_run1[nick] = 0
            decisions_run2[nick] = 0

        for message in messages:
            type_addiction_decision[message["nick"]] = random.choice(type_addiction_list)




        data1_run0 = {
            "predictions": decisions_run0,
            "emissions": emissions
        }
        data1_run1 = {
            "predictions": decisions_run1,
            "emissions": emissions
        }
        data1_run2 = {
            "predictions": decisions_run2,
            "emissions": emissions
        }
        data2_run0 = {
            "predictions": decisions_run0,
            "types":type_addiction_decision,
            "emissions": emissions
        }
        data2_run1 = {
            "predictions": decisions_run1,
            "types":type_addiction_decision,
            "emissions": emissions
        }
        data2_run2 = {
            "predictions": decisions_run2,
            "types":type_addiction_decision,
            "emissions": emissions
        }

        data1 = []
        data1.append(json.dumps(data1_run0))
        data1.append(json.dumps(data1_run1))
        data1.append(json.dumps(data1_run2))

        data2 = []
        data2.append(json.dumps(data2_run0))
        data2.append(json.dumps(data2_run1))
        data2.append(json.dumps(data2_run2))

        # Session to POST request
        session = requests.Session()
        retries = Retry(
                        total = retries,
                        backoff_factor = backoff,
                        status_forcelist = [500, 502, 503, 504]
                        )
        session.mount('https://', HTTPAdapter(max_retries=retries))

        for run in range(0, self.number_of_runs):
            # For each run, new decisions
            response1 = session.post(ENDPOINT_SUBMIT_DECISIONS.format(TASK='task1', TOKEN=self.token, RUN=run), json=[data1[run]]) # ENDPOINT
            if response1.status_code != 200:
                print("POST - Task1 - Status Code {} - Error: {}".format(str(response1.status_code), str(response1.text)))
                return
            else:
                print("POST - Task1 - run {} - Message: {}".format(run, str(response1.text)))

            response2 = session.post(ENDPOINT_SUBMIT_DECISIONS.format(TASK='task2', TOKEN=self.token, RUN=run), json=[data2[run]]) # ENDPOINT
            if response2.status_code != 200:
                print("POST - Task2 - Status Code {} - Error: {}".format(str(response2.status_code), str(response2.text)))
                return
            else:
                print("POST - Task2 - run {} - Message: {}".format(run, str(response2.text)))
            """
            with open('./data/preds/task1/round{}_run{}.json'.format(messages[0]["round"], run), 'w+', encoding='utf8') as json_file:
                json.dump(data1[run], json_file, ensure_ascii=False)
            with open('./data/preds/task2/round{}_run{}.json'.format(messages[0]["round"], run), 'w+', encoding='utf8') as json_file:
                json.dump(data2[run], json_file, ensure_ascii=False)
            """

            #Añadir los usuarios detectados a los usuarios mandados, para no procesarlos más
            self.sended_users_run1 += self.flagged_users_run1
            self.sended_users_run2 += self.flagged_users_run2
            self.sended_users_run3 += self.flagged_users_run3
            self.round_users = set()
    def run_task1_2(self, retries: int, backoff: float):
        """ Main thread
            Args:
              retries (int): number of calls on the server connection
              backoff (float): time between retries
        """
        # Get messages for task1_2
        messages = self.get_messages(retries, backoff)
        for msg in messages:
            nick = msg["nick"]
            self.total_users.add(nick)
        # If there are no messages
        if len(messages) == 0:
            print("All rounds processed")
            return

        while len(messages) > 0:
            print(f"------------------\n{len(messages)}\n-----------------")
            sys.stdout.reconfigure(encoding='utf-8')  

            print("----------------------- Processing round {}".format(messages[0]["round"]))
            # Save subjects
            #with open('./data/rounds/round{}.json'.format(messages[0]["round"]), 'w+', encoding='utf8') as json_file:
            #    json.dump(messages, json_file, ensure_ascii=False)

            # Calculate emissions for each prediction
            self.tracker.start()  
            for msg in messages:
                nick = msg["nick"]
                self.round_users.add(nick)
                text = msg["message"]
            #RUN1
                if nick not in self.sended_users_run1:
                    embedding = self.embedder.encode(text)
                    new_prob = self.model.predict_proba([embedding])[0][1]
                    if nick in self.user_probs:
                        self.user_probs[nick] = (self.user_probs[nick] + new_prob) / 2
                    else:
                        self.user_probs[nick] = new_prob
                    if self.user_probs[nick] > self.THRESHOLD:
                        self.flagged_users_run1.append(nick)
            #RUN2
                if nick not in self.sended_users_run2:
                    if nick not in self.user_texts:
                        self.user_texts[nick] = text
                    else:
                        self.user_texts[nick] += " " + text

                    full_text = self.user_texts[nick]
                    embedding = self.embedder.encode(full_text)
                    prob_risk = self.model.predict_proba([embedding])[0][1]

                    if prob_risk > self.THRESHOLD:
                        self.flagged_users_run2.append(nick)
            #RUN3
                if nick not in self.sended_users_run3:
                    prob_risk = self.model_mensajes.predict_proba([text])[0][1]
                    if prob_risk > self.THRESHOLD_msg:
                        self.flagged_users_run3.append(nick)


            emissions = self.tracker.stop()
            df = pd.read_csv("emissions.csv")
            measurements = df.iloc[-1][self.relevant_cols].to_dict()

            self.submit_decission(messages, measurements, retries, backoff)

            # One GET request for each round
            messages = self.get_messages(retries, backoff)

        print("All rounds processed")
        
"""# Main"""

def download_data(task: str, token: str):
    download_messages_trial(task, token)

def get_post_data(task: str, token: str):
    # Emissions Tracker Config
    config = {
        "save_to_file": True,
        "log_level": "WARNING",
        "tracking_mode": "process",
        "output_dir": ".",
        "allow_multiple_runs": True
    }
    tracker = EmissionsTracker(**config)

    number_runs = 3 # Max: 3

    # Prediction period
    client_task1_2 = Client_task1_2(task, token, number_runs, tracker)
    client_task1_2.run_task1_2(5, 0.1)

"""Be careful! In this specific example we use the name of the task1 to do the get, knowing that it is the same data for both task 1 and task 2. In addition, the data upload is performed for both tasks."""

if __name__ == '__main__':
    get_post_data("task1",TOKEN)
